{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b6f2fb8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################################################\n",
    "# Author 1:      Jakob Marktl\n",
    "# MatNr 1:       12335939\n",
    "# Author 2:      Christoph Nagy\n",
    "# MatNr 2:       12331569\n",
    "# Author 3:      Maria Mikic\n",
    "# MatNr 3:       12234490\n",
    "# File:          notebook.ipynb\n",
    "# Description:   A simple baseline classifier that makes predictions based on a specified strategy.\n",
    "# Comments:    ... comments for the tutors ...\n",
    "#              ... can be multiline ...\n",
    "################################################################################\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "69934831",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy==2.3.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from -r ./assignment2/requirements.txt (line 1)) (2.3.0)\n",
      "Requirement already satisfied: pandas==2.3.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from -r ./assignment2/requirements.txt (line 2)) (2.3.0)\n",
      "Requirement already satisfied: scipy==1.15.3 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from -r ./assignment2/requirements.txt (line 3)) (1.15.3)\n",
      "Requirement already satisfied: plotly==6.1.2 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from -r ./assignment2/requirements.txt (line 4)) (6.1.2)\n",
      "Requirement already satisfied: scikit-learn==1.7.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from -r ./assignment2/requirements.txt (line 5)) (1.7.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/mariamikic/Library/Python/3.12/lib/python/site-packages (from pandas==2.3.0->-r ./assignment2/requirements.txt (line 2)) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from pandas==2.3.0->-r ./assignment2/requirements.txt (line 2)) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from pandas==2.3.0->-r ./assignment2/requirements.txt (line 2)) (2025.2)\n",
      "Requirement already satisfied: narwhals>=1.15.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from plotly==6.1.2->-r ./assignment2/requirements.txt (line 4)) (1.43.1)\n",
      "Requirement already satisfied: packaging in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from plotly==6.1.2->-r ./assignment2/requirements.txt (line 4)) (25.0)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from scikit-learn==1.7.0->-r ./assignment2/requirements.txt (line 5)) (1.5.1)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from scikit-learn==1.7.0->-r ./assignment2/requirements.txt (line 5)) (3.6.0)\n",
      "Requirement already satisfied: six>=1.5 in /Users/mariamikic/Library/Python/3.12/lib/python/site-packages (from python-dateutil>=2.8.2->pandas==2.3.0->-r ./assignment2/requirements.txt (line 2)) (1.17.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -r \"./assignment2/requirements.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "376b6555",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%reload_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f1911bd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from pandas import DataFrame\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
    "\n",
    "from assignment2.datasetClassifier import (\n",
    "    DatasetHandler,\n",
    "    DecisionTreeClassifier,\n",
    "    GaussianNBClassifier,\n",
    "    KNNClassifier,\n",
    "    LogisticRegressionClassifier,\n",
    "    RandomForestClassifierModel,\n",
    "    SVMClassifier,\n",
    ")\n",
    "from assignment2.datasetPreProcessor import DatasetPreprocessor\n",
    "from assignment2.graphing import Graphing\n",
    "from assignment2.simpleBaselineClassifier import SimpleBaselineClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "09f600b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved cleaned CSV to cleaned_dataset.csv\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1044 entries, 0 to 1043\n",
      "Data columns (total 33 columns):\n",
      " #   Column      Non-Null Count  Dtype\n",
      "---  ------      --------------  -----\n",
      " 0   school      1044 non-null   int64\n",
      " 1   sex         1044 non-null   int64\n",
      " 2   age         1044 non-null   int64\n",
      " 3   address     1044 non-null   int64\n",
      " 4   famsize     1044 non-null   int64\n",
      " 5   Pstatus     1044 non-null   int64\n",
      " 6   Medu        1044 non-null   int64\n",
      " 7   Fedu        1044 non-null   int64\n",
      " 8   Mjob        1044 non-null   int64\n",
      " 9   Fjob        1044 non-null   int64\n",
      " 10  reason      1044 non-null   int64\n",
      " 11  guardian    1044 non-null   int64\n",
      " 12  traveltime  1044 non-null   int64\n",
      " 13  studytime   1044 non-null   int64\n",
      " 14  failures    1044 non-null   int64\n",
      " 15  schoolsup   1044 non-null   int64\n",
      " 16  famsup      1044 non-null   int64\n",
      " 17  paid        1044 non-null   int64\n",
      " 18  activities  1044 non-null   int64\n",
      " 19  nursery     1044 non-null   int64\n",
      " 20  higher      1044 non-null   int64\n",
      " 21  internet    1044 non-null   int64\n",
      " 22  romantic    1044 non-null   int64\n",
      " 23  famrel      1044 non-null   int64\n",
      " 24  freetime    1044 non-null   int64\n",
      " 25  goout       1044 non-null   int64\n",
      " 26  Dalc        1044 non-null   int64\n",
      " 27  Walc        1044 non-null   int64\n",
      " 28  health      1044 non-null   int64\n",
      " 29  absences    1044 non-null   int64\n",
      " 30  G1          1044 non-null   int64\n",
      " 31  G2          1044 non-null   int64\n",
      " 32  G3          1044 non-null   int64\n",
      "dtypes: int64(33)\n",
      "memory usage: 269.3 KB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mariamikic/Informatik_2/assignment2/Informatik_2-1/assignment2/assignment2/datasetPreProcessor.py:73: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df[col] = df[col].replace(mapping)\n",
      "/Users/mariamikic/Informatik_2/assignment2/Informatik_2-1/assignment2/assignment2/datasetPreProcessor.py:76: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df.replace({\"yes\": 1, \"no\": 0}, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "dataset_path = \"cleaned_dataset.csv\"\n",
    "\n",
    "preprocessor = DatasetPreprocessor(\"student+performance.zip\")\n",
    "preprocessor.to_csv(dataset_path)\n",
    "\n",
    "df: DataFrame = preprocessor.data\n",
    "\n",
    "df.describe()\n",
    "df.value_counts()\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d03112da",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "classifiers = {\n",
    "    \"GaussianNB\": GaussianNBClassifier(),\n",
    "    \"DecisionTree\": DecisionTreeClassifier(),\n",
    "    \"KNN\": KNNClassifier(k=5),\n",
    "    \"RandomForest\": RandomForestClassifierModel(n_estimators=100, random_state=0),\n",
    "    \"SVMClassifier\": SVMClassifier(kernel=\"rbf\", c=1.0),\n",
    "    \"LogisticRegression\": LogisticRegressionClassifier(max_iter=5000, random_state=0),\n",
    "    \"SBC_most_frequent\": SimpleBaselineClassifier(\"most_frequent\"),\n",
    "    \"SBC_uniform\": SimpleBaselineClassifier(\"uniform\", random_state=3),\n",
    "    \"SBC_constant\": SimpleBaselineClassifier(\"constant\", constant=3)\n",
    "}\n",
    "\n",
    "dataset_handler = DatasetHandler(dataset_path)\n",
    "graphing = Graphing(dataset_handler)\n",
    "\n",
    "y_preds = {}\n",
    "metrics = {\n",
    "    \"Accuracy\": [],\n",
    "    \"Precision\": [],\n",
    "    \"Recall\": [],\n",
    "    \"F1 Score\": []\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9164a690",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for name, clf in classifiers.items():\n",
    "    clf.fit(dataset_handler.x_train, dataset_handler.y_train)\n",
    "    y_pred = clf.predict(dataset_handler.x_test)\n",
    "    y_preds[name] = y_pred\n",
    "\n",
    "    metrics[\"Accuracy\"].append(accuracy_score(dataset_handler.y_test, y_pred))\n",
    "    metrics[\"Precision\"].append(precision_score(dataset_handler.y_test, y_pred, average='macro', zero_division=0))\n",
    "    metrics[\"Recall\"].append(recall_score(dataset_handler.y_test, y_pred, average='macro'))\n",
    "    metrics[\"F1 Score\"].append(f1_score(dataset_handler.y_test, y_pred, average='macro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2415890a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature ranking:\n",
      "1. Feature G2 (0.3044)\n",
      "2. Feature G1 (0.1714)\n",
      "3. Feature absences (0.0460)\n",
      "4. Feature health (0.0288)\n",
      "5. Feature Walc (0.0270)\n",
      "6. Feature Dalc (0.0260)\n",
      "7. Feature goout (0.0247)\n",
      "8. Feature freetime (0.0244)\n",
      "9. Feature famrel (0.0236)\n",
      "10. Feature romantic (0.0236)\n",
      "11. Feature internet (0.0232)\n",
      "12. Feature higher (0.0225)\n",
      "13. Feature nursery (0.0222)\n",
      "14. Feature activities (0.0218)\n",
      "15. Feature paid (0.0212)\n",
      "16. Feature famsup (0.0212)\n",
      "17. Feature schoolsup (0.0171)\n",
      "18. Feature failures (0.0157)\n",
      "19. Feature studytime (0.0136)\n",
      "20. Feature traveltime (0.0120)\n",
      "21. Feature guardian (0.0111)\n",
      "22. Feature reason (0.0111)\n",
      "23. Feature Fjob (0.0109)\n",
      "24. Feature Mjob (0.0101)\n",
      "25. Feature Fedu (0.0099)\n",
      "26. Feature Medu (0.0097)\n",
      "27. Feature Pstatus (0.0095)\n",
      "28. Feature famsize (0.0092)\n",
      "29. Feature address (0.0076)\n",
      "30. Feature age (0.0075)\n",
      "31. Feature sex (0.0068)\n",
      "32. Feature school (0.0062)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Mime type rendering requires nbformat>=4.2.0 but it is not installed",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m importances = np.sort(classifiers[\u001b[33m'\u001b[39m\u001b[33mRandomForest\u001b[39m\u001b[33m'\u001b[39m].feature_importances)\n\u001b[32m      2\u001b[39m graphing.print_feature_importances(importances)\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m \u001b[43mgraphing\u001b[49m\u001b[43m.\u001b[49m\u001b[43mplot_feature_importances\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimportances\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Informatik_2/assignment2/Informatik_2-1/assignment2/assignment2/graphing.py:58\u001b[39m, in \u001b[36mGraphing.plot_feature_importances\u001b[39m\u001b[34m(self, importances)\u001b[39m\n\u001b[32m     47\u001b[39m fig = go.Figure(\n\u001b[32m     48\u001b[39m     go.Bar(\n\u001b[32m     49\u001b[39m         x=sorted_features,\n\u001b[32m     50\u001b[39m         y=sorted_importances,\n\u001b[32m     51\u001b[39m     )\n\u001b[32m     52\u001b[39m )\n\u001b[32m     53\u001b[39m fig.update_layout(\n\u001b[32m     54\u001b[39m     title=\u001b[33m\"\u001b[39m\u001b[33mFeature Importances\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     55\u001b[39m     xaxis_title=\u001b[33m\"\u001b[39m\u001b[33mFeature\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     56\u001b[39m     yaxis_title=\u001b[33m\"\u001b[39m\u001b[33mImportance\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     57\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m58\u001b[39m \u001b[43mfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mshow\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/plotly/basedatatypes.py:3436\u001b[39m, in \u001b[36mBaseFigure.show\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   3403\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   3404\u001b[39m \u001b[33;03mShow a figure using either the default renderer(s) or the renderer(s)\u001b[39;00m\n\u001b[32m   3405\u001b[39m \u001b[33;03mspecified by the renderer argument\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   3432\u001b[39m \u001b[33;03mNone\u001b[39;00m\n\u001b[32m   3433\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   3434\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mplotly\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mio\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpio\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m3436\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mpio\u001b[49m\u001b[43m.\u001b[49m\u001b[43mshow\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/plotly/io/_renderers.py:425\u001b[39m, in \u001b[36mshow\u001b[39m\u001b[34m(fig, renderer, validate, **kwargs)\u001b[39m\n\u001b[32m    420\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    421\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mMime type rendering requires ipython but it is not installed\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    422\u001b[39m     )\n\u001b[32m    424\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m nbformat \u001b[38;5;129;01mor\u001b[39;00m Version(nbformat.__version__) < Version(\u001b[33m\"\u001b[39m\u001b[33m4.2.0\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m425\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    426\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mMime type rendering requires nbformat>=4.2.0 but it is not installed\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    427\u001b[39m     )\n\u001b[32m    429\u001b[39m display_jupyter_version_warnings()\n\u001b[32m    431\u001b[39m ipython_display.display(bundle, raw=\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[31mValueError\u001b[39m: Mime type rendering requires nbformat>=4.2.0 but it is not installed"
     ]
    }
   ],
   "source": [
    "importances = np.sort(classifiers['RandomForest'].feature_importances)\n",
    "graphing.print_feature_importances(importances)\n",
    "graphing.plot_feature_importances(importances)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffc33ba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "graphing.plot_feature_correspondence([\"G1\", \"G2\", \"absences\", \"Walc\", \"age\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "271d77e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "for name in classifiers.keys():\n",
    "    y_pred = y_preds[name]\n",
    "    graphing.plot_confusion_matrix(dataset_handler.y_test, y_pred, name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92a710f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "graphing.plot_evaluation_metrics(list(classifiers.keys()), metrics, title=\"Evaluation Metrics by Classifier with average=macro\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afec1b24",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_micro = {\n",
    "    \"Accuracy\": [],\n",
    "    \"Precision\": [],\n",
    "    \"Recall\": [],\n",
    "    \"F1 Score\": []\n",
    "}\n",
    "for name in classifiers:\n",
    "    y_pred = y_preds[name]\n",
    "\n",
    "    metrics_micro[\"Accuracy\"].append(accuracy_score(dataset_handler.y_test, y_pred))\n",
    "    metrics_micro[\"Precision\"].append(precision_score(dataset_handler.y_test, y_pred, average=\"micro\"))\n",
    "    metrics_micro[\"Recall\"].append(recall_score(dataset_handler.y_test, y_pred, average=\"micro\"))\n",
    "    metrics_micro[\"F1 Score\"].append(f1_score(dataset_handler.y_test, y_pred, average=\"micro\"))\n",
    "graphing.plot_evaluation_metrics(list(classifiers.keys()), metrics_micro, title=\"Evaluation Metrics by Classifier with average=micro\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df061725",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_weighted = {\n",
    "    \"Accuracy\": [],\n",
    "    \"Precision\": [],\n",
    "    \"Recall\": [],\n",
    "    \"F1 Score\": []\n",
    "}\n",
    "for name in classifiers:\n",
    "    y_pred = y_preds[name]\n",
    "\n",
    "    metrics_weighted[\"Accuracy\"].append(accuracy_score(dataset_handler.y_test, y_pred))\n",
    "    metrics_weighted[\"Precision\"].append(precision_score(dataset_handler.y_test, y_pred, average=\"weighted\", zero_division=0))\n",
    "    metrics_weighted[\"Recall\"].append(recall_score(dataset_handler.y_test, y_pred, average=\"weighted\"))\n",
    "    metrics_weighted[\"F1 Score\"].append(f1_score(dataset_handler.y_test, y_pred, average=\"weighted\"))\n",
    "graphing.plot_evaluation_metrics(list(classifiers.keys()), metrics_weighted, title=\"Evaluation Metrics by Classifier with average=weighted\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
